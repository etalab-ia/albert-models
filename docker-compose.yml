version: "3.8"

services:
  vllm:
    image: vllm/vllm-openai:latest
    command: --model $LLM_HF_REPO_ID $VLLM_ARGS
    environment:
      - VLLM_API_KEY=${API_KEY}
      - HF_TOKEN=${HF_TOKEN}
    env_file: .env
    volumes:
      - ${MODELS_CACHE_DIR:-"./models"}/${LLM_HF_REPO_ID}:/root/.cache/huggingface
    ipc: host
    expose:
      - 8000
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:latest
    command: --model-id $EMBEDDINGS_HF_REPO_ID $TEI_ARGS
    environment:
      - API_KEY=${API_KEY}
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    volumes:
      - ${MODELS_CACHE_DIR:-"./models"}/${EMBEDDINGS_HF_REPO_ID}:/data
    expose:
      - 80
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  fastapi:
    image: ghcr.io/etalab-ia/albert-models/fastapi:latest
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    environment:
      - API_KEY=${API_KEY}
    expose:
      - 8000
    restart: always

  nginx:
    image: ghcr.io/etalab-ia/albert-models/nginx:latest
    ports:
      - 8080:8080
    restart: always
