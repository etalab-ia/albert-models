# Hugging Face embeddings model repository ID
EMBEDDINGS_HF_REPO_ID=intfloat/e5-small

# Hugging Face LLM model repository ID
LLM_HF_REPO_ID=TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ

# Embeddings args
TEXT_EMBEDDINGS_INFERENCE_ARGS=--max-client-batch-size 64

# LLM args
VLLM_ARGS=--quantization gptq --dtype half --tensor-parallel-size 1 --gpu-memory-utilization 0.4

# models cache directory
MODELS_CACHE_DIR=~/models

# docker-compose project name
COMPOSE_PROJECT_NAME=serve
